# Project List

To understand the projects we're going to do and choose the one you're interested in, you should first take a look at this webpage. Information is subject to amendments over the semester.

## Web Scraping Indian NGOs Information using GitHub Actions

**Project Description:**

The goal of this project is to create a comprehensive database of Indian NGOs by extracting information from various websites and sources, and automate the web scraping workflow using GitHub Actions. This information will include registration details, contact information, funding sources, and other relevant data. The project will use web scraping techniques and libraries such as Scrapy or Beautiful Soup to extract the data.

**Tasks:**

- Research and identify relevant websites and sources of information for Indian NGOs
- Develop web scraping scripts using Python and web scraping libraries such as Scrapy or Beautiful Soup
- Extract data from websites including registration details, contact information, funding sources and other relevant data
- Clean and process the data, removing duplicates and formatting it in a structured format.
- Store the data in a database such as PostgreSQL
- Create visualizations and reports to understand the data and insights
- Automate the web scraping workflow using [GitHub actions](https://www.swyx.io/github-scraping), which will run the web scraping scripts, process and save the data, and update the database.

**Technologies:**

- Python
- Web scraping libraries (Scrapy, Beautiful Soup)
- SQL
- PostgreSQL or other database management systems
- GitHub Actions

**Expected Outcomes:**

- A comprehensive database of Indian NGOs that includes registration details, contact information, funding sources and other relevant data
- Data visualization and reports that provide insights into the Indian NGO sector.
- A library of web scraping scripts that can be used for future data collection and updates
- A fully automated web scraping workflow using GitHub Actions, that will allow for regular updates and maintenance of the database.

Note: The project description is a general guidance, and the specific tasks, technologies and outcomes may vary depending on the scope of the project and the data availability. Additionally, web scraping can be against the website's term of service, it's important to check the website's policy and also use the scraping tools in a responsible way.

When learning Python web scraping, you will gain knowledge and skills in the following areas:

1. HTML and CSS: Web scraping involves extracting data from websites, which are written in HTML and CSS. Understanding the structure and elements of HTML and CSS is crucial for being able to locate and extract the desired data from a webpage.
2. HTTP and web protocols: Web scraping requires making HTTP requests to a website and understanding the web protocols such as GET, POST and handling cookies and sessions.
3. XPath and CSS selectors: To extract data from a webpage, you'll need to be able to locate the relevant elements on the page. This can be done using XPath and CSS selectors, which are used to navigate and select elements in an HTML or XML document.
4. Web scraping libraries: Python offers a variety of libraries for web scraping such as Scrapy, Beautiful Soup, Selenium among others, you will learn how to use them to extract data from websites in a fast and efficient way.
5. Data processing and data structures: After extracting data from a website, you will need to process and structure the data. This may involve cleaning, normalizing and transforming the data so it can be used for further analysis.
6. Web scraping best practices: Web scraping can be against the website's term of service and can also cause issues on the website's performance, so it's important to learn about best practices like respecting robots.txt, using APIs when possible and being mindful of the scraping frequency.
7. Ethics and legal considerations: Web scraping can raise legal and ethical issues, it's important to learn the legal framework and ethical considerations around web scraping.

By learning Python web scraping, you will gain the skills and knowledge needed to extract data from websites and use it to drive business decisions, research, and more.

```{dropdown} Webscraping libraries
- **Scrapy:** It is an open-source and collaborative web crawling framework for Python. Scrapy allows you to extract data from websites using spiders, which are scripts that navigate through a website and extract the desired information. Scrapy also provides a built-in way to follow links, handle cookies and sessions, and handle pagination, making it a powerful tool for web scraping.
- **Beautiful Soup:** This is a Python library that allows you to parse HTML and XML documents, and extract data from them. Beautiful Soup is not as robust as Scrapy in terms of handling sessions and pagination but it is simpler to use and is good for small web scraping projects, it's also helpful when you want to extract data from a single page.
Both libraries are free and open-source, and have an active community that provides support and tutorials.

It's worth noting that web scraping can be against the website's term of service and can also cause issues on the website's performance, it's important to check the website's policy and also use the scraping tools in a responsible way.
```

## Indian NGOs Registration Document Library and Categorization

**Project Description:**

The goal of this project is to create a comprehensive library of all the registration documents that an NGO in India needs. The project will involve researching and identifying all the registration documents required for an NGO to operate in India and then creating a library that is easily accessible for anyone interested in setting up an NGO.

**Tasks:**

- Research and identify all the registration documents required for an NGO to operate in India
- Gather information on registration process, required documents, and any other relevant details
- Create a user-friendly interface for searching and accessing the library

**Technologies:**

- Python
- Web scraping libraries (Scrapy, Beautiful Soup)
- SQL
- PostgreSQL or other database management systems

**Expected Outcomes:**

- A comprehensive library of all the registration documents required for an NGO to operate in India
- A user-friendly interface for searching and accessing the library
- Data visualization and reports that provide insights into the Indian NGO sector
- Continuously updated library with new information and changes in the regulations

Note: The project description is a general guidance, and the specific tasks, technologies and outcomes may vary depending on the scope of the project and the data availability. Additionally, web scraping can be against the website's term of service, it's important to check the website's policy and also use the scraping tools in a responsible way.

NGOs in India are required to register with different government agencies depending on their type and activities. The registration documents needed will vary depending on the specific NGO and the agency with which it is registering. However, here are some of the types of registration documents that are commonly needed for NGOs in India:

- FCRA registration: Foreign Contribution Regulation Act (FCRA) registration is required for NGOs that receive foreign funding. This registration is done with the Ministry of Home Affairs.
- 12A registration: Section 12A registration is required for NGOs that are eligible for tax exemptions under the Income Tax Act. This registration is done with the Income Tax Department.
- 80G registration: Section 80G registration is required for NGOs that are eligible for tax exemptions under the Income Tax Act on donations made to them. This registration is done with the Income Tax Department.
- MSME registration: MSME registration is required for NGOs that are involved in micro, small and medium enterprises. This registration is done with the Ministry of Micro, Small and Medium Enterprises.
- TAN registration: Tax Deduction and Collection Account Number (TAN) registration is required for NGOs that are required to deduct or collect tax. This registration is done with the Income Tax Department.
- PAN registration: Permanent Account Number (PAN) registration is required for all organizations, including NGOs, that are required to pay taxes. This registration is done with the Income Tax Department.
- GST registration: Goods and Services Tax (GST) registration is required for NGOs that are involved in commercial activities and are required to pay GST. This registration is done with the Central Board of Indirect Taxes and Customs.
- Society registration: Society registration is required for NGOs that are registered as a society. This registration is done with the Registrar of Societies.
- Trust registration: Trust registration is required for NGOs that are registered as a trust. This registration is done with the Registrar of Trusts.

In India, most of the registration documents for NGOs are considered public information and can be obtained by interested parties through various means.

The registration documents for an NGO that are considered public information are:

FCRA registration: This registration is maintained by the Ministry of Home Affairs and the information on the registration and the annual returns filed by the NGO are available on the Ministry's website for the public to access.
12A, 80G, MSME, TAN, PAN, GST, Society and Trust registration: These registration details are maintained by the respective government agencies and can be accessed through their websites or by contacting them directly.
However, some information may be considered confidential and may not be available to the public, such as personal details of the NGO's members or donors. Additionally, certain registration documents like FCRA, may contain information that is not available to the public due to security and privacy concerns.

It's important to note that there may be some variations depending on the state laws and regulations, it's advisable to check with the relevant authorities for the specific registration process and documents availability.
